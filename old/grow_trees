#!/usr/bin/env python3
import json

import numpy as np
import numpy.random as rand
import scipy.io as io

from neural_trees import *

################################################################################
# Data Loading
################################################################################

mnist = io.loadmat('mnist.mat')

x_tr = np.vstack([mnist['train%i' % i].T for i in range(10)])
x_ts = np.vstack([mnist['test%i' % i].T for i in range(10)])

y_tr = np.int32(np.vstack([
    i * np.ones((mnist['train%i' % i].shape[1], 1))
    for i in range(10)]))
y_ts = np.int32(np.vstack([
    i * np.ones((mnist['test%i' % i].shape[1], 1))
    for i in range(10)]))

################################################################################
# Logging
################################################################################

def layer_desc(layer):
    return {'size': int(layer.w.shape[0].eval()),
            'op_count': int(layer.tf.n_ops),
            'children': [layer_desc(ch) for ch in layer.children]}

def net_desc(net, **hyperparams):
    n_cor = 10 * [None]
    n_inc = 10 * [None]
    for i in range(10):
        x_i = x_ts[(y_ts == i)[:, 0]]
        y_est = net.classify(x_i)
        δ_cor = y_est == i
        δ_inc = (y_est >= 0) * (y_est < 10) * (y_est != i)
        n_cor[i] = np.sum(δ_cor, axis=0)
        n_inc[i] = np.sum(δ_inc, axis=0)
    l = 0
    root = layer_desc(net.root)
    def annotate(layer):
        nonlocal l
        layer['n_correct'] = np.array(n_cor)[:, l].tolist()
        layer['n_incorrect'] = np.array(n_inc)[:, l].tolist()
        l += 1
        for child in layer['children']:
            annotate(child)
    annotate(root)
    return {'hyperparams': hyperparams, 'root': root}

################################################################################
# Network Training and Evaluation
################################################################################

layer_size = 256
k_cpts = [2e-7]
k_l2 = np.float32(1e-6)
k_lyr = np.float32(5e-3)
w_scale = np.float32(1e-3)
ϵ = np.float32(0.5)
λ = np.float32(1e-2)
batch_size = 32
n_epochs = 200

def train_1_epoch(net, k_cpt):
    order = rand.permutation(x_tr.shape[0])
    x = np.take(x_tr, order, axis=0)
    y = np.take(y_tr, order, axis=0)
    losses = []
    costs = []
    for i in range(0, x_tr.shape[0] - batch_size, batch_size):
        l, c = net.train(x[i:i+batch_size], y[i:i+batch_size], k_cpt, k_l2, ϵ, λ)
        losses.append(l)
        costs.append(c)
    return np.mean(costs)

def extensions(net):
    def extensions_from(layer):
        new_tf = ReLuTF(layer.tf.n_out, layer_size, w_scale)
        new_layer = Layer(layer_size, 10, w_scale, new_tf, [])
        return ([layer.clone_adding(new_layer)] +
                [layer.clone_replacing(i, ext)
                 for i, ch in enumerate(layer.children)
                 for ext in extensions_from(ch)])
    return [Net(ext) for ext in extensions_from(net.root)]

results = []

for k_cpt in k_cpts:
    curr_net = Net(Layer(784, 10, w_scale, IdentityTF(784), []))
    cand_nets = extensions(curr_net)
    print('Training a network with k_cpt=%.1e...' % k_cpt)
    for t in range(n_epochs):
        curr_cost = train_1_epoch(curr_net, k_cpt)
        cand_costs = [train_1_epoch(net, k_cpt) for net in cand_nets]
        all_costs = [curr_cost] + cand_costs
        print(('Finished epoch %i.' % t) + ' costs=' + str(all_costs))
        if min(cand_costs) + k_lyr < curr_cost:
            i_best = np.argmin(cand_costs)
            curr_net = cand_nets[i_best]
            cand_nets = extensions(curr_net)
            print('Added candidate layer %i.' % i_best)
        if t % 10 == 0:
            n_lab = np.max(y_ts) + 1
            y_est = curr_net.classify(x_ts)
            δ_cor = y_est == y_ts
            δ_inc = (y_est >= 0) * (y_est < n_lab) * (y_est != y_ts)
            n_cor = np.sum(δ_cor, axis=0).tolist()
            n_inc = np.sum(δ_inc, axis=0).tolist()
            acc = np.sum(n_cor) / x_ts.shape[0]
            print('============================================================')
            print('Epoch', t)
            print('============================================================')
            print('n_correct:', n_cor)
            print('n_incorrect:', n_inc)
            print('accuracy:', acc)
    desc = net_desc(
        curr_net, k_l2=float(k_l2), k_cpt=float(k_cpt), w_scale=float(w_scale),
        ϵ=float(ϵ), λ=float(λ), batch_size=batch_size, n_epochs=n_epochs)
    print('Trained net:', desc)
    results.append(desc)

with open('experiment_1.json', 'w') as f:
    f.write(json.dumps(
        results, sort_keys=True, indent=2,
        separators=(',', ': ')))
