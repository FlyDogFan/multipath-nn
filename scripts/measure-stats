#!/usr/bin/env python3
'''
Measure network performance statistics.
'''
from argparse import ArgumentParser
from json import dumps
from os import makedirs
from os.path import isfile

import tensorflow as tf

from exp.dr_cifar import exp_specs
from lib.desc import net_desc
from lib.serdes import read_net

################################################################################
# Define network statistics.
################################################################################

def p_cor_by_cls(net, ℓ):
    return tf.expand_dims(ℓ.p_ev * ℓ.δ_cor, 1) * net.y

def p_inc_by_cls(net, ℓ):
    return tf.expand_dims(ℓ.p_ev * (1 - ℓ.δ_cor), 1) * net.y

def state_tensors(net):
    return {(net, 'acc'): sum(ℓ.p_ev * ℓ.δ_cor for ℓ in net.leaves),
            (net, 'moc'): sum(ℓ.p_ev * ℓ.n_ops for ℓ in net.layers),
            **{(ℓ, 'p_cor'): ℓ.p_ev * ℓ.δ_cor for ℓ in net.leaves},
            **{(ℓ, 'p_inc'): ℓ.p_ev * (1 - ℓ.δ_cor) for ℓ in net.leaves},
            **{(ℓ, 'p_cor_by_cls'): p_cor_by_cls(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'p_inc_by_cls'): p_inc_by_cls(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'c_err'): ℓ.c_err for ℓ in net.leaves},
            **{(ℓ, 'c_err_cor'): ℓ.c_err_cor for ℓ in net.leaves
               if hasattr(ℓ, 'c_err_cor')}}

################################################################################
# Parse command-line arguments.
################################################################################

parser = ArgumentParser(description=__doc__)
parser.add_argument('target', help='the network type to analyze',
                    choices=exp_specs.keys())

args = parser.parse_args()

################################################################################
# Train networks.
################################################################################

dataset = exp_specs[args.target].dataset()
log = []

for i in range(len(exp_specs[args.target].nets)):
    if isfile('nets/%s/net%i.tfn' % (args.target, i)):
        with tf.Graph().as_default():
            sess = tf.Session()
            with sess.as_default():
                net = read_net('nets/%s/net%i.npy' % (args.target, i))
                log.append(net_desc(net, dataset, {}, state_tensors(net)))

makedirs('stats', exist_ok=True)
with open('stats/%s.json' % args.target, 'w') as f:
    f.write(dumps(log, indent=2))
