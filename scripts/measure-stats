#!/usr/bin/env python3
'''
Measure network performance statistics.
'''
from argparse import ArgumentParser
from json import dumps
from os import makedirs
from os.path import isfile

import numpy as np
import tensorflow as tf

from lib.desc import net_desc
from exp.dr_cifar import exp_specs, read_dataset, w_cls

################################################################################
# Define network statistics.
################################################################################

def p_cor(net, ℓ):
    y_sup = tf.matmul(net.y, w_cls)
    δ_cor = tf.equal(tf.argmax(ℓ.x, 1), tf.argmax(y_sup, 1))
    return ℓ.p_ev * tf.to_float(δ_cor)

def p_inc(net, ℓ):
    y_sup = tf.matmul(net.y, w_cls)
    δ_inc = tf.not_equal(tf.argmax(ℓ.x, 1), tf.argmax(y_sup, 1))
    return ℓ.p_ev * tf.to_float(δ_inc)

def p_cor_by_cls(net, ℓ):
    return tf.expand_dims(p_cor(net, ℓ), 1) * net.y

def p_inc_by_cls(net, ℓ):
    return tf.expand_dims(p_inc(net, ℓ), 1) * net.y

def acc_and_moc(net):
    return {(net, 'acc'): sum(p_cor(net, ℓ) for ℓ in net.leaves),
            (net, 'moc'): sum(ℓ.p_ev * ℓ.n_ops for ℓ in net.layers),
            **{(ℓ, 'p_cor'): p_cor(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'p_inc'): p_inc(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'p_cor_by_cls'): p_cor_by_cls(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'p_inc_by_cls'): p_inc_by_cls(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'c_err'): ℓ.c_err for ℓ in net.leaves},
            **{(ℓ, 'c_err_cor'): ℓ.c_err_cor for ℓ in net.leaves
               if hasattr(ℓ, 'c_err_cor')}}

################################################################################
# Parse command-line arguments.
################################################################################

parser = ArgumentParser(description=__doc__)
parser.add_argument('target', help='the network type to analyze',
                    choices=exp_specs.keys())

args = parser.parse_args()

################################################################################
# Load data.
################################################################################

dataset = read_dataset()

################################################################################
# Train networks.
################################################################################

log = []

for i, (net_constr, validate) in enumerate(exp_specs[args.target]):
    if isfile('nets/%s/net%i.tfn' % (args.target, i)):
        with tf.Graph().as_default():
            net = net_constr()
            net.read('nets/%s/net%i.tfn' % (args.target, i))
            log.append(net_desc(net, dataset, {}, acc_and_moc(net)))

makedirs('stats', exist_ok=True)
with open('stats/%s.json' % src, 'w') as f:
    f.write(dumps(log, indent=2))
