#!/usr/bin/env python3
'''
Measure network performance statistics.
'''
from json import dumps
from os import makedirs
from os.path import isfile

import numpy as np
import tensorflow as tf

from lib.desc import net_desc
from exp.dr_cifar import (
    cr_chain, cr_tree, ds_chain, ds_tree, read_dataset, sr_chain, w_cls)

################################################################################
# Load data.
################################################################################

dataset = read_dataset()

################################################################################
# Define network statistics.
################################################################################

def p_cor(net, ℓ):
    y_sup = tf.matmul(net.y, w_cls)
    δ_cor = tf.equal(tf.argmax(ℓ.x, 1), tf.argmax(y_sup, 1))
    return ℓ.p_ev * tf.to_float(δ_cor)

def p_inc(net, ℓ):
    y_sup = tf.matmul(net.y, w_cls)
    δ_inc = tf.not_equal(tf.argmax(ℓ.x, 1), tf.argmax(y_sup, 1))
    return ℓ.p_ev * tf.to_float(δ_inc)

def p_cor_by_cls(net, ℓ):
    return tf.expand_dims(p_cor(net, ℓ), 1) * net.y

def p_inc_by_cls(net, ℓ):
    return tf.expand_dims(p_inc(net, ℓ), 1) * net.y

def acc_and_moc(net):
    return {(net, 'acc'): sum(p_cor(net, ℓ) for ℓ in net.leaves),
            (net, 'moc'): sum(ℓ.p_ev * ℓ.n_ops for ℓ in net.layers),
            **{(ℓ, 'p_cor'): p_cor(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'p_inc'): p_inc(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'p_cor_by_cls'): p_cor_by_cls(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'p_inc_by_cls'): p_inc_by_cls(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'c_err'): ℓ.c_err for ℓ in net.leaves},
            **{(ℓ, 'c_err_cor'): ℓ.c_err_cor for ℓ in net.leaves
               if hasattr(ℓ, 'c_err_cor')}}

################################################################################
# Ensure that the output directory exists.
################################################################################

makedirs('stats', exist_ok=True)

################################################################################
# Measure the statistics of all trained nets.
################################################################################

def measure_stats(src, net_constr):
    log = []
    i = 0
    while isfile('nets/%s/net%i.tfn' % (src, i)):
        with tf.Graph().as_default():
            net = net_constr(i)
            net.read('nets/%s/net%i.tfn' % (src, i))
            log.append(net_desc(net, dataset, {}, acc_and_moc(net)))
        i += 1
    with open('stats/%s.json' % src, 'w') as f:
        f.write(dumps(log, indent=2))

measure_stats('sr-chains', lambda i: sr_chain(i))
measure_stats('ds-chains', lambda i: ds_chain())
measure_stats('ds-chains-em', lambda i: ds_chain())
measure_stats('cr-chains', lambda i: cr_chain())
measure_stats('cr-chains-em', lambda i: cr_chain())
measure_stats('ds-trees', lambda i: ds_tree())
measure_stats('cr-trees', lambda i: cr_tree())
