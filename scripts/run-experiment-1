#!/usr/bin/env python3
'''
Compare the accuracy and efficiency of decision smoothing and cost regression
networks.
'''
from json import dumps
from os import makedirs

import tensorflow as tf

from lib.data import Dataset
from lib.layers import (
    BatchNorm, Chain, CrossEntropyError, LinTrans, MultiscaleConvMax,
    MultiscaleLLN, Rect, SelectPyramidTop, Softmax, ToPyramid)
from lib.nets import CRNet, DSNet, SRNet
from lib.training import train

################################################################################
# Load data.
################################################################################

dataset = Dataset('data/cifar-10.mat')
x0_shape = dataset.x0_shape
y_shape = dataset.y_shape

################################################################################
# Define network hyperparameters.
################################################################################

t_train = tf.placeholder(tf.float32, ())
λ_learn = 0.1 / 2**(t_train // 10)
optimizer = tf.train.MomentumOptimizer(λ_learn, 0.9)
route_stat = t_train < 1
k_cpt = 1e-9
k_l2 = 1e-3
ϵ = 0.1
τ = 1

################################################################################
# Define network components.
################################################################################

class ToPyramidLLN(Chain):
    def __init__(self, shape0, n_scales):
        super().__init__(
            ToPyramid(n_scales=n_scales),
            MultiscaleLLN(shape0=shape0),
            BatchNorm())

class ReConvMax(Chain):
    def __init__(self, shape0, n_scales, n_chan):
        super().__init__(
            MultiscaleConvMax(
                shape0=shape0, n_scales=n_scales,
                n_chan=n_chan, supp=3, k_l2=k_l2, σ_w=1e-2),
            BatchNorm(), Rect())

class LogReg(Chain):
    def __init__(self, shape0):
        super().__init__(
            SelectPyramidTop(shape0=shape0),
            LinTrans(n_chan=y_shape[0], k_l2=k_l2, σ_w=1e-2),
            Softmax(), CrossEntropyError())

def router_gen(ℓ):
    return Chain(
        SelectPyramidTop(shape0=(4, 4)),
        LinTrans(n_chan=16, k_l2=k_l2), Rect(),
        LinTrans(n_chan=len(ℓ.sinks), k_l2=k_l2))

################################################################################
# Allocate a log for the experiment results.
################################################################################

log = {'sr': [], 'dr': []}

################################################################################
# Train a statically-routed network.
################################################################################

print('\n —— Training a statically-routed network... ——\n')

net = SRNet(
    x0_shape, y_shape, optimizer,
    [ToPyramidLLN((32, 32), 4),
        [ReConvMax((32, 32), 4, 32),
        [ReConvMax((32, 32), 4, 32),
        [ReConvMax((32, 32), 4, 32),
            [ReConvMax((32, 32), 3, 64),
            [ReConvMax((16, 16), 3, 64),
            [ReConvMax((16, 16), 3, 64),
                [ReConvMax((16, 16), 2, 128),
                [ReConvMax((8, 8), 2, 128),
                [ReConvMax((8, 8), 2, 128),
                    LogReg((8, 8))]]]]]]]]]])

log['sr'] = train(
    net, dataset, logging_period=1,
    name='Statically-Routed Network',
    hypers=(lambda t: {t_train: t}))

################################################################################
# Train a dynamically-routed network
################################################################################

print('\n —— Training a dynamically-routed network... ——\n')

net = DSNet(
    x0_shape, y_shape, router_gen, optimizer,
    dict(k_cpt=k_cpt, k_l2=k_l2, ϵ=ϵ, τ=τ, route_stat=route_stat),
    [ToPyramidLLN((32, 32), 4), LogReg((32, 32)),
        [ReConvMax((32, 32), 4, 32), LogReg((32, 32)),
        [ReConvMax((32, 32), 4, 32), LogReg((32, 32)),
        [ReConvMax((32, 32), 4, 32), LogReg((32, 32)),
            [ReConvMax((32, 32), 3, 64), LogReg((16, 16)),
            [ReConvMax((16, 16), 3, 64), LogReg((16, 16)),
            [ReConvMax((16, 16), 3, 64), LogReg((16, 16)),
                [ReConvMax((16, 16), 2, 128), LogReg((8, 8)),
                [ReConvMax((8, 8), 2, 128), LogReg((8, 8)),
                [ReConvMax((8, 8), 2, 128), LogReg((8, 8))]]]]]]]]]])

log['dr'] = train(
    net, dataset, logging_period=1,
    name='Dynamically-Routed Network',
    hypers=(lambda t: {t_train: t}))

################################################################################
# Save the results.
################################################################################

makedirs('nets/', exist_ok=True)
with open('nets/experiment-1.json', 'w') as f:
    f.write(dumps(log, sort_keys=True, indent=2, separators=(',', ': ')))

print('\n —— Saved the results as `nets/experiment-1.json`. ——\n')
