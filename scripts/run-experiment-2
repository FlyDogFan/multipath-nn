#!/usr/bin/env python3
'''
Compare the accuracy and efficiency of decision smoothing and cost regression
networks.
'''
from json import dumps
from os import makedirs

from lib.data import Dataset
from lib.nets import CRRouting, DSRouting, LogReg, Net, ReConv, ReConvMP
from lib.training import train

################################################################################
# Load data.
################################################################################

dataset = Dataset('data/cifar-10.mat')
x0_shape = dataset.x0_shape
y_shape = dataset.y_shape
n_cls = y_shape[0]

################################################################################
# Define network hyperparameters.
################################################################################

k_cpts = [0] + [4**i * 1e-10 for i in range(7)]
k_cre = 0.1
λ = 0.8
ϵ = 0.5

################################################################################
# Allocate a log for the experiment results.
################################################################################

log = {'sr': None, 'ds': [], 'cr': []}

################################################################################
# Train a statically-routed network.
################################################################################

print('\n —— Training a statically-routed network... ——\n')

sr_net = Net(x0_shape, y_shape,
    ReConv(64, 1, 3, 0, λ,
    ReConvMP(64, 2, 3, 0, λ,
        ReConv(128, 1, 3, 0, λ,
        ReConvMP(128, 2, 3, 0, λ,
            ReConv(256, 1, 3, 0, λ,
            ReConvMP(256, 2, 3, 0, λ,
                LogReg(n_cls))))))))

log['sr'] = train(sr_net, dataset, 'Static Routing',
                  n_epochs=100, logging_period=5)

exit()

################################################################################
# Train decision smoothing networks.
################################################################################

print('\n —— Training decision smoothing networks... ——\n')

for k_cpt in k_cpts:
    net = Net(x0_shape, y_shape, DSRouting(ϵ, LogReg(n_cls),
        ReConv(32, 1, 3, k_cpt, λ, DSRouting(ϵ, LogReg(n_cls),
        ReConvMP(32, 2, 3, k_cpt, λ, DSRouting(ϵ, LogReg(n_cls),
            ReConv(64, 1, 3, k_cpt, λ, DSRouting(ϵ, LogReg(n_cls),
            ReConvMP(64, 2, 3, k_cpt, λ, DSRouting(ϵ, LogReg(n_cls),
                ReConv(128, 1, 3, k_cpt, λ, DSRouting(ϵ, LogReg(n_cls),
                ReConvMP(128, 2, 3, k_cpt, λ, LogReg(n_cls))))))))))))))
    name = 'Decision Smoothing (k_cpt=%.1e)' % k_cpt
    desc = train(net, dataset, name, n_epochs=50)
    log['ds'].append({'k_cpt': k_cpt, 'net': desc})

################################################################################
# Train cost regressing networks.
################################################################################

print('\n —— Training cost regression networks... ——\n')

for k_cpt in k_cpts:
    net = Net(x0_shape, y_shape, CRRouting(k_cre, ϵ, LogReg(n_cls),
        ReConv(32, 1, 3, k_cpt, λ, CRRouting(k_cre, ϵ, LogReg(n_cls),
        ReConvMP(32, 2, 3, k_cpt, λ, CRRouting(k_cre, ϵ, LogReg(n_cls),
            ReConv(64, 1, 3, k_cpt, λ, CRRouting(k_cre, ϵ, LogReg(n_cls),
            ReConvMP(64, 2, 3, k_cpt, λ, CRRouting(k_cre, ϵ, LogReg(n_cls),
                ReConv(128, 1, 3, k_cpt, λ, CRRouting(k_cre, ϵ, LogReg(n_cls),
                ReConvMP(128, 2, 3, k_cpt, λ, LogReg(n_cls))))))))))))))
    name = 'Cost Regression (k_cpt=%.1e)' % k_cpt
    desc = train(net, dataset, name, n_epochs=50)
    log['cr'].append({'k_cpt': k_cpt, 'net': desc})

################################################################################
# Save the results.
################################################################################

makedirs('nets/', exist_ok=True)
with open('nets/experiment-2.json', 'w') as f:
    f.write(dumps(log, sort_keys=True, indent=2, separators=(',', ': ')))

print('\n —— Saved the results as `nets/experiment-2.json`. ——\n')
