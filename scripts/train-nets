#!/usr/bin/env python3
'''
Train statically- or dynamically-routed networks.
'''
from argparse import ArgumentParser
from os import makedirs
from types import SimpleNamespace as Ns

import numpy as np
import numpy.random as rand
import tensorflow as tf

from lib.data import Dataset
from lib.desc import net_desc, render_net_desc
from lib.layer_types import (
    BatchNorm, Chain, CrossEntropyError, LinTrans, MultiscaleBatchNorm,
    MultiscaleConvMax, MultiscaleLLN, MultiscaleRect, Rect, Select,
    Softmax, ToPyramid)

from lib.net_types import AcNet, CRNet, DSNet, SRNet
from lib.serdes import write_net

################################################################################
# Define network hyperparameters.
################################################################################

conv_supp = 3
router_n_chan = 16

k_cpts = [0.0, 1e-9, 2e-9, 4e-9, 8e-9, 1.6e-8, 3.2e-8, 6.4e-8]
k_l2 = 1e-4
σ_w = 1

x0_shape = (32, 32, 3)
y_shape = (8,)

arch = [
    [16, 16, 16, 16],
    [16, 16, 16, 16],
    [32, 32, 32],
    [32, 32, 32],
    [64, 64],
    [64, 64],
    [128],
    [128]]

################################################################################
# Define training hyperparameters.
################################################################################

n_iter = 60000
t_log = 2500
batch_size = 128

n_vl = 1280
p_vl = 0.05

λ_lrn_0 = 0.1
t_anneal = 5000

################################################################################
# Define network components.
################################################################################

def router(n_sinks):
    return None if n_sinks < 2 else Chain(name='Router', comps=[
        Select(i=-1), LinTrans(n_chan=router_n_chan, k_l2=k_l2, σ_w=σ_w),
        BatchNorm(), Rect(), LinTrans(n_chan=n_sinks, k_l2=k_l2, σ_w=0)])

def pyr(*sinks):
    return Chain(
        name='ToPyramidLLN', sinks=sinks,
        router=router(len(sinks)), comps=[
            ToPyramid(n_scales=len(arch[0])),
            MultiscaleLLN(), MultiscaleBatchNorm()])

def rcm(i, *sinks):
    return Chain(
        name='ReConvMax', sinks=sinks,
        router=router(len(sinks)), comps=[
            MultiscaleConvMax(
                n_chan=arch[i], supp=conv_supp,
                k_l2=k_l2, σ_w=σ_w),
            MultiscaleBatchNorm(), MultiscaleRect()])

def reg():
    return Chain(name='LogReg', comps=[
        Select(i=-1),
        LinTrans(n_chan=y_shape[0], k_l2=k_l2, σ_w=σ_w),
        Softmax(), CrossEntropyError()])

################################################################################
# Define network constructors.
################################################################################

def sr_chain(n_tf):
    def make_net():
        root = reg()
        for i in reversed(range(n_tf)):
            root = rcm(i, root)
        root = pyr(root)
        return SRNet(
            x0_shape=x0_shape,
            y_shape=y_shape,
            root=root)
    return make_net

def dr_chain(type_, **hypers):
    def make_net():
        root = rcm(-1, reg())
        for i in reversed(range(len(arch) - 1)):
            root = rcm(i, reg(), root)
        root = pyr(root)
        return type_(
            x0_shape=x0_shape, y_shape=y_shape,
            root=root, **hypers)
    return make_net

def dr_tree(type_, **hypers):
    def make_net():
        root = pyr(
            rcm(0, reg(),
            rcm(1, reg(),
                rcm(2, reg(),
                rcm(3, reg(),
                    rcm(4, reg(),
                    rcm(5, reg())),
                    rcm(4, reg(),
                    rcm(5, reg())))),
                rcm(2, reg(),
                rcm(3, reg(),
                    rcm(4, reg(),
                    rcm(5, reg())),
                    rcm(4, reg(),
                    rcm(5, reg())))))))
        return type_(
            x0_shape=x0_shape, y_shape=y_shape,
            root=root, **hypers)
    return make_net

################################################################################
# Define experiments.
################################################################################

sr_hypers = lambda net, t: {}
ds_hypers = lambda net, t: {net.ϵ: 0.5 / 2**(t / 10000)}
ac_hypers = lambda net, t: {net.ϵ: 0.5 / 2**(t / 10000)}
cr_hypers = lambda net, t: {net.τ: 0.1 / 2**(t / 15000)}

experiments = {
    'sr-chains': Ns(
        nets=[sr_chain(n) for n in range(1, len(arch) + 1)],
        augment=True, use_em=False, hypers=sr_hypers),
    'sr-chains-noaug': Ns(
        nets=[sr_chain(n) for n in range(1, len(arch) + 1)],
        augment=False, use_em=False, hypers=sr_hypers),
    'ds-chains': Ns(
        nets=[dr_chain(DSNet, k_cpt=k) for k in k_cpts],
        augment=True, use_em=False, hypers=ds_hypers),
    'cr-chains': Ns(
        nets=[dr_chain(CRNet, k_cpt=k) for k in k_cpts],
        augment=True, use_em=False, hypers=cr_hypers),
    'ac-chains': Ns(
        nets=[dr_chain(AcNet, k_cpt=k) for k in k_cpts],
        augment=True, use_em=False, hypers=ac_hypers),
    'ac-chains-opt': Ns(
        nets=[dr_chain(AcNet, k_cpt=k, optimistic=True) for k in k_cpts],
        augment=True, use_em=False, hypers=ac_hypers),
    'ac-chains-noaug': Ns(
        nets=[dr_chain(AcNet, k_cpt=k) for k in k_cpts],
        augment=False, use_em=False, hypers=ac_hypers),
    'ac-chains-noaug-em': Ns(
        nets=[dr_chain(AcNet, k_cpt=k) for k in k_cpts],
        augment=True, use_em=True, hypers=ac_hypers),
    'ac-trees': Ns(
        nets=[dr_tree(CRNet, k_cpt=k) for k in k_cpts],
        augment=True, use_em=False, hypers=ac_hypers)}

################################################################################
# Parse command-line arguments.
################################################################################

parser = ArgumentParser(description=__doc__)
parser.add_argument('expt', help='the experiment to perform',
                    choices=experiments.keys())

expt_name = parser.parse_args().expt
expt = experiments[expt_name]

################################################################################
# Load the dataset.
################################################################################

dataset = Dataset('data/hybrid.npz', expt.use_em * n_vl)

################################################################################
# Train networks.
################################################################################

def p_cor_by_cls(net, ℓ):
    return tf.expand_dims(ℓ.p_ev * ℓ.δ_cor, 1) * net.y

def p_inc_by_cls(net, ℓ):
    return tf.expand_dims(ℓ.p_ev * (1 - ℓ.δ_cor), 1) * net.y

def state_tensors(net):
    tot_n_ops = lambda ℓ: ℓ.n_ops + getattr(ℓ.router, 'n_ops', 0)
    return {(net, 'acc'): sum(ℓ.p_ev * ℓ.δ_cor for ℓ in net.leaves),
            (net, 'moc'): sum(ℓ.p_ev * tot_n_ops(ℓ) for ℓ in net.layers),
            **{(ℓ, 'p_cor'): ℓ.p_ev * ℓ.δ_cor for ℓ in net.leaves},
            **{(ℓ, 'p_inc'): ℓ.p_ev * (1 - ℓ.δ_cor) for ℓ in net.leaves},
            **{(ℓ, 'p_cor_by_cls'): p_cor_by_cls(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'p_inc_by_cls'): p_inc_by_cls(net, ℓ) for ℓ in net.leaves},
            **{(ℓ, 'c_err'): ℓ.c_err for ℓ in net.leaves},
            **{(ℓ, 'c_err_cor'): ℓ.c_err_cor for ℓ in net.leaves
               if hasattr(ℓ, 'c_err_cor')}}

def train_net(i):
    expt = experiments[expt_name]
    net = expt.nets[i]()
    net_state = state_tensors(net)
    tf.initialize_all_variables().run()
    for t in range(n_iter):
        x0, y = (
            dataset.augmented_training_batch(batch_size) if expt.augment
            else dataset.training_batch(batch_size))
        ϕ = expt.hypers(net, t)
        print('  --- Iteration %i ---\r' % (t + 1), end='', flush=True)
        net.train.run({
            net.x0: x0, net.y: y, net.mode: 'tr',
            net.λ_lrn: λ_lrn_0 / 2**(t / t_anneal), **ϕ})
        if expt.use_em and rand.rand() < p_vl:
            x0, y = dataset.validation_batch(batch_size)
            net.validate.run({net.x0: x0, net.y: y, net.mode: 'vl', **ϕ})
        if (t + 1) % t_log == 0:
            desc = net_desc(net, dataset, ϕ, net_state)
            text = render_net_desc(desc, '%s — Epoch %i' % (expt_name, t + 1))
            makedirs('net/%s' % expt_name, exist_ok=True)
            np.save('net/%s/%.4i-stats.npy' % (expt_name, i), desc)
            with open('net/%s/%.4i-log.txt' % (expt_name, i), 'a+') as f:
                f.write(text + '\n')
            print(text)
    makedirs('net/%s' % expt_name, exist_ok=True)
    write_net('net/%s/%.4i.npy' % (expt_name, i), net)

for i in range(len(expt.nets)):
    with tf.Graph().as_default():
        sess = tf.Session(config=tf.ConfigProto(
            gpu_options=tf.GPUOptions(allow_growth=True)))
        with sess.as_default():
            train_net(i)
